The European Rover Challenge Final Task simulates a Martian surface exploration scenario, where the objective is to remotely investigate the crash site of a previous expedition. In this mission, we were tasked with identifying objects of interest scattered across the Marsyard environment, assessing their relevance, and reporting our findings in a structured and detailed manner. Our primary goal was to generate a comprehensive report of the crash site using visual data. The task involved detecting objects â€” both native to a Martian setting (such as rocks) and assessing their utility, origin, and potential value to the mission. To fulfill this objective, we utilized a semi-autonomous approach that combined real-time teleoperation with AI-assisted visual perception. Object detection and scene understanding were performed using computer vision techniques , while localization relied on AR tags and onboard odometry. Report generation was semi-automated using large language models (LLMs) to ensure consistency, clarity, and structured formatting. This report presents our findings, including object descriptions, visual evidence, location annotations, and relevance assessments, along with reflections on the robot's performance and safety mechanisms during the task execution.
